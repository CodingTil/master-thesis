\section{Dantzig-Wolfe Reformulation}\label{sec:cg_bp_dwr}
The column generation algorithm presented in Section \ref{sec:cg_bp_cg} is particularly useful when we can directly formulate our optimization problem using a master and a pricing problem. However, many problems are provided in the general form of a \LP{}. Using the Dantzig-Wolfe reformulation, we can transform such a \LP{} into a master and pricing problem, making it suitable for column generation \cite{thebook}. This section introduces this technique and demonstrates how it can be applied to solve a \LP{}.

\begin{equation}
\begin{aligned}
z^*_\LP{} = &\min & \vec{c}\transpose \vec{x} & & & \\
&\st & \mat{A} \vec{x} & \geq \vec{b} & \left[\vec{\sigma}_\vec{b}\right] & \\
&& \mat{D} \vec{x} & \geq \vec{d} & \left[\vec{\sigma}_\vec{d}\right] & \\
&& \vec{x} & \geq \vec{0}
\end{aligned}
\end{equation}

Consider the above \LP{}. The solution space defined by its constraints can be viewed as the intersection of the following two polyhedra:

\begin{equation}
\begin{aligned}
\polyhedron{A} &\coloneqq \left\{ \vec{x} \geq \vec{0} \mid \mat{A} \vec{x} \geq \vec{b} \right\} &\neq \emptyset \\
\polyhedron{D} &\coloneqq \left\{ \vec{x} \geq \vec{0} \mid \mat{D} \vec{x} \geq \vec{d} \right\} &\neq \emptyset
\end{aligned}
\end{equation}

Applying the Nemhauser-Wolsey Theorem (Theorem \ref{th:nemhauser-wolsey}) on polyhedron $\polyhedron{D}$, we can reformulate the \LP{} using $\polyhedron{D}$'s extreme points $\{\vec{x}_p\}_{p \in P}$ and extreme rays $\{\vec{x}_r\}_{r \in R}$. To achieve this, we substitute the original variables $\vec{x}$ with these extreme points and extreme rays using:

\begin{equation}
\begin{aligned}
\vec{x} &= \sum_{p \in P} \vec{x}_p \lambda_p + \sum_{r \in R} \vec{x}_r \lambda_r \\
\vec{c}\transpose \vec{x} &= \sum_{p \in P} \vec{c}\transpose \vec{x}_p \lambda_p + \sum_{r \in R} \vec{c}\transpose \vec{x}_r \lambda_r \\
\mat{A} \vec{x} &= \sum_{p \in P} \mat{A} \vec{x}_p \lambda_p + \sum_{r \in R} \mat{A} \vec{x}_r \lambda_r
\end{aligned}
\end{equation}

Using the following shorthand notations:

\begin{equation}
\begin{aligned}
c_p &\coloneqq \vec{c}\transpose \vec{x}_p
&c_r &\coloneqq \vec{c}\transpose \vec{x}_r \\
\vec{a}_p &\coloneqq \mat{A} \vec{x}_p
&\vec{a}_r &\coloneqq \mat{A} \vec{x}_r
\end{aligned}
\end{equation}

We obtain a new \MP{} equivalent to the \LP{}:

\begin{equation}
\begin{aligned}
z^*_\MP{} = &\min & \sum_{p \in P} c_p \lambda_p &+ &\sum_{r \in R} c_r \lambda_r & & & \\
&\st & \sum_{p \in P} \vec{a}_p \lambda_p &+ &\sum_{r \in R} \vec{a}_r \lambda_r & \geq \vec{b} & \left[\vec{\pi}_\vec{b}\right] \\
&& \sum_{p \in P} \lambda_p & & & = 1 & \left[\pi_0 \right] & \\
&& \lambda_p & & & \geq 0 & & \forall p \in P \\
&& & & \lambda_r & \geq 0 & & \forall r \in R \\
&& \sum_{p \in P} \vec{x}_p \lambda_p &+ &\sum_{r \in R} \vec{x}_r \lambda_r & = \vec{x} \geq \vec{0} & &
\end{aligned}
\end{equation}

In this formulation, the last constraint corresponds to projecting a solution of the \MP{} using the $\lambda$ variables back into a solution of the original \LP{}. As this constraint is not otherwise involved in the optimization, it is often omitted during the solving stages and only used afterward to reconstruct a solution using the original $\vec{x}$ variables \cite{thebook}.

Since the extreme points and extreme rays of $\polyhedron{D}$ are often unknown, and their number might be enormous, solving the \MP{} directly is typically infeasible \cite{thebook}. Instead, we can generate these columns on the fly using column generation. For this, we need a subproblem that finds (improving) columns for the \MP{}, i.e., extreme points and extreme rays of $\polyhedron{D}$. We can formulate this pricing problem as follows:

\begin{equation}
\begin{aligned}
z^*_\SP{} = &\min & \left( \vec{c}\transpose - \vec{\pi}_\vec{b}\transpose \mat{A} \right) \vec{x} - \pi_0 & & \\
&\st & \mat{D} \vec{x} & \geq \vec{d} & \left[\vec{\pi}_\vec{d}\right] \\
&& \vec{x} & \geq \vec{0}
\end{aligned}
\end{equation}

We start by solving the \RMP{} using a subset of the extreme points $P' \subset P$ and extreme rays $R' \subset R$, yielding the dual values $\vec{\pi}_\vec{b}$ and $\pi_0$ for the \SP{}. Solving this \SP{} to optimality then leads to a solution $\vec{x}^*$ with objective value $z^*_\SP{}$. The value of $z^*_\SP{}$ determines whether we add a column to \RMP{}, and if so, which column to add:

\begin{itemize}
\item If $-\infty < z^*_\SP{} < 0$, $\vec{x}^*$ is an extreme point $\vec{x}_p, p \in P \setminus P'$, and we add column $\begin{bmatrix} \vec{c}\transpose \vec{x}^* \\ \mat{A} \vec{x}^* \\ 1 \end{bmatrix}$ to \RMP{}.
\item If $z^*_\SP{} = -\infty$, $\vec{x}^*$ is an extreme ray $\vec{x}_r, r \in R \setminus R'$, and we add column $\begin{bmatrix} \vec{c}\transpose \vec{x}^* \\ \mat{A} \vec{x}^* \\ 0 \end{bmatrix}$ to \RMP{}.
\item If $z^*_\SP{} \geq 0$, there exists no improving column for \RMP{}, and the column generation algorithm terminates.
\end{itemize}

While theoretically, the grouping of constraints in the original \LP{} formulation for the Dantzig-Wolfe reformulation does not change the optimal solution, in practice, the choice of grouping can significantly impact the performance of the column generation algorithm. Since many iterations of the column generation algorithm are often required to find an optimal solution, ideally, one wants \SP{} to be efficiently solvable. Numerous efficient algorithms for specific optimization problems exist, and by grouping constraints in a way that \SP{} corresponds to such structures, one can leverage these algorithms to solve \SP{} efficiently \cite{thebook}. Although there are ways to find such groupings automatically, this topic is beyond the scope of this thesis.
