\section{Column Generation}\label{sec:cg_bp_cg}
Consider the following linear program, referred to as \textbf{master problem} \MP{}, where $c_\vec{x} \in \mathbb{R}, \vec{a}_\vec{x}, \vec{b} \in \mathbb{R}^m, \forall \vec{x} \in \indexset{X}$:

\begin{equation}
\begin{aligned}
z^*_\MP{} = &\min & \sum_{\vec{x} \in \indexset{X}} c_\vec{x} \lambda_\vec{x} & & & \\
&\st & \sum_{\vec{x} \in \indexset{X}} \vec{a}_\vec{x} \lambda_\vec{x} & \geq \vec{b} & \left[\vec{\pi}\right] & \\
&& \lambda_\vec{x} & \geq 0 & & \forall \vec{x} \in \indexset{X}
\end{aligned}
\end{equation}

Assume the number of variables is significantly larger than the number of constraints ($m \ll \abs{\indexset{X}} < \infty$). Because of this, solving \MP{} directly in a reasonable time frame, or at all, is often infeasible \cite{thebook}.

However, we can utilize a crucial property of the primal simplex algorithm: at any given vertex solution, only few variables are in the basis. Most variables are in the non-basis and therefore have a solution value of $0$. Having a solution value of $0$ is equivalent to not being in the linear program at all. Therefore, the primal simplex algorithm can operate using a manageable subset of variables $\indexset{X}' \subseteq \indexset{X}$, finding a feasible, though possibly non-optimal, solution for \MP{}. This master problem restricted to a subset of variables is called the \textbf{restricted master problem} \RMP{}:

\begin{equation}
\begin{aligned}
z^*_\RMP{} = &\min & \sum_{\vec{x} \in \indexset{X}'} c_\vec{x} \lambda_\vec{x} & & & \\
&\st & \sum_{\vec{x} \in \indexset{X}'} \vec{a}_\vec{x} \lambda_\vec{x} & \geq \vec{b} & \left[\vec{\pi}\right] & \\
&& \lambda_\vec{x} & \geq 0 & & \forall \vec{x} \in \indexset{X}'
\end{aligned}
\end{equation}

Assuming \MP{} is feasible, two important questions arise for finding an optimal solution to \MP{} by solving \RMP{}: first, how do we select a subset $\indexset{X}'$ of variables, such that \RMP{} remains feasible? Without this property, no solution for \RMP{} can be found, which would contradict the feasibility of \MP{}. Secondly, assuming a solution for \RMP{} is found, possibly even optimal for the \RMP{}, how can we extend this solution to eventually find an optimal solution for \MP{}?

The following sections address these questions in detail (Sections \ref{sec:cg_bp_cg_farkas} and \ref{sec:cg_bp_cg_reduced}), leading to the complete column generation algorithm (Section \ref{sec:cg_bp_cg_alg}).

\subsection{Farkas Pricing \FP{}}\label{sec:cg_bp_cg_farkas}
Assume \MP{} is feasible, but the current selection of variables $\indexset{X}' \subset \indexset{X}$ results in \RMP{} being infeasible. The task is to find additional variables such that a new set $\indexset{X}''$ with $\indexset{X}' \subset \indexset{X}'' \subseteq \indexset{X}$ makes \RMP{} feasible. Consider Farkas' lemma:

\begin{theorem}[Farkas' lemma \cite{matouvsek2007understanding,thebook}]\label{th:farkas_lemma}
Given $\mat{A} \in \mathbb{R}^{m \times n}$ and $\vec{b} \in \mathbb{R}^m$, then exactly one of the following statements holds:
\begin{enumerate}
	\item $\exists \vec{x} \in \mathbb{R}_+^n. \, \mat{A} \vec{x} \geq \vec{b}$
	\item $\exists \vec{\pi} \in \mathbb{R}^m. \, \vec{\pi}\transpose \mat{A} \leq \vec{0} \land \vec{\pi}\transpose \vec{b} > 0$
\end{enumerate}
\end{theorem}

Given that \MP{} is feasible, the following must hold for \MP{} with $\mat{A} = \mat{A}_{\vert \indexset{X}}$:

\begin{equation}
\begin{aligned}
\neg & \exists \vec{\pi} \in \mathbb{R}^m. \, \vec{\pi}\transpose \mat{A} \leq \vec{0} \land \vec{\pi}\transpose \vec{b} > 0 \\
\Leftrightarrow & \forall \vec{\pi} \in \mathbb{R}^m. \, \neg \left( \vec{\pi}\transpose \mat{A} \leq \vec{0} \land \vec{\pi}\transpose \vec{b} > 0 \right)\\
\Leftrightarrow & \forall \vec{\pi} \in \mathbb{R}^m. \, \vec{\pi}\transpose \mat{A} > \vec{0} \lor \vec{\pi}\transpose \vec{b} \leq 0
\end{aligned}
\end{equation}

Considering the infeasibility of \RMP{} we can further derive the following statement:

\begin{equation}
\begin{aligned}
& \left( \forall \vec{\pi} \in \mathbb{R}^m. \, \vec{\pi}\transpose \mat{A} > \vec{0} \lor \vec{\pi}\transpose \vec{b} \leq 0 \right) \land \left( \exists \vec{\pi} \in \mathbb{R}^m. \, \vec{\pi}\transpose \mat{A}_{\vert \indexset{X}'} \leq \vec{0} \land \vec{\pi}\transpose \vec{b} > 0 \right) \\
\Rightarrow & \left( \neg \forall \vec{\pi} \in \mathbb{R}^m. \, \vec{\pi}\transpose \vec{b} \leq 0 \right) \land \left( \exists \vec{\pi} \in \mathbb{R}^m. \, \vec{\pi}\transpose \mat{A} > \vec{0} \right)
\end{aligned}
\end{equation}

Therefore, there exists some variable $\vec{x} \in \indexset{X} \setminus \indexset{X}'$ such that its column $\vec{a}_\vec{x} \coloneqq \mat{A}_{\vert \{\vec{x}\}}$ satisfies $\vec{\pi}\transpose \vec{a}_\vec{x} > 0$ for some $\vec{\pi} \in \mathbb{R}^m$. If none existed, \MP{} would not be feasible.

This process of finding corresponding columns $\vec{a}_\vec{x}$ to add to \RMP{} can be formalized as a pricing problem with cost coefficients $c_\vec{x} = 0$ (see Equation \eqref{eq:psa_pp}). Let us denote this subproblem as the \FP{}:

\begin{equation}
\operatorname{F}(\vec{\pi}) = \underset{x \in \indexset{X}}{\min} \, -\vec{\pi}\transpose \vec{a}_x
\end{equation}

We can add all solutions $\vec{x}$ with a value of $\operatorname{F}(\vec{\pi}) < 0$ to $\indexset{X}'' \coloneqq \indexset{X}' \cup \{\vec{x}_i\}$, adding the corresponding column $\begin{bmatrix}0 \\ \vec{a}_\vec{x} \end{bmatrix}$ to the problem, thus turning any infeasible \RMP{} feasible \cite{thebook}.

\subsection{Reduced Cost Pricing \RCP{}}\label{sec:cg_bp_cg_reduced}
Assume \RMP{} is feasible. Using an appropriate solver, we can construct a solution that is optimal within \RMP{}, providing us with the dual values $\vec{\pi}$. We now need to verify whether this solution is also optimal for \MP{}. For this, we can use the familiar pricing problem from the primal simplex algorithm (see Equation \eqref{eq:psa_pp}). Let us denote this subproblem as the \RCP{}:

\begin{equation}
\bar{c}(\vec{\pi}) = \underset{\vec{x} \in \indexset{X}}{\min} \, c_\vec{x} - \vec{\pi}\transpose \vec{a}_\vec{x}
\end{equation}

If $\bar{c}(\vec{\pi}) \geq 0$, no cost-improving column exists and we have proven the optimality of the current solution for \MP{}. Otherwise, if $\bar{c}(\vec{\pi}) < 0$, there exists some $\vec{x} \in \indexset{X} \setminus \indexset{X}'$ with $\bar{c}(\vec{\pi}) = c_\vec{x} - \vec{\pi}\transpose \vec{a}_\vec{x} < 0$. Similar to how the primal simplex algorithm would swap this variable into the basis, during column generation we add the corresponding column $\begin{bmatrix} c_\vec{x} \\ \vec{a}_\vec{x} \end{bmatrix}$ to \RMP{} \cite{thebook}. This process ensures that \RMP{} remains feasible.

\begin{algorithm}
\caption{Column Generation Algorithm}
\KwIn{\RMP{} with subset $\indexset{X}' \subseteq \indexset{X}$, \RCP{}, \FP{}}
\KwOut{Optimal Solution $(\vec{\lambda}, z)$ for the \MP{}}
\While{$\operatorname{IsInfeasible}(\RMP{})$}{
	$\left(\None, \vec{\pi}\right) \gets \operatorname{Solve}(\RMP{})$\;
	$\left(\vec{x}, \operatorname{F}(\vec{\pi})\right) \gets \operatorname{Solve}(\FP{}, \vec{\pi})$\;
	\If{$\operatorname{F}(\vec{\pi}) \geq 0$}{
		\Return{\None} \textit{by \MP{} infeasibility}
	}
	$\indexset{X}' \gets \indexset{X}' \cup \{\vec{x}\}$\;
	$\mat{A} \gets \begin{bmatrix} \mat{A} & \vec{a}_\vec{x} \end{bmatrix}$\;
}

\Loop{
	$\left(\vec{\lambda}_\RMP{}, \vec{\pi} \right) \gets \operatorname{Solve}(\RMP{})$\;
	$\left(\vec{x}, \bar{c}(\vec{\pi})\right) \gets \operatorname{Solve}(\RCP{}, \vec{\pi})$\;
	\If{$\bar{c}(\vec{\pi}) \geq 0$}{
		\Return{$\left(\vec{\lambda}_\RMP{}, \vec{c}_\indexset{B}\transpose \vec{x}_\indexset{B}\right)$} \textit{by optimality}
	}
	$\indexset{X}' \gets \indexset{X}' \cup \{\vec{x}\}$\;
	$\mat{A} \gets \begin{bmatrix} \mat{A} & \vec{a}_\vec{x} \end{bmatrix}$\;
}
\end{algorithm}

\subsection{Column Generation Algorithm}\label{sec:cg_bp_cg_alg}
The column generation algorithm can be viewed as a variation of the primal simplex algorithm. We start by solving the \MP{} with a subset of the original variables, initialized either as an empty set or using some selection heuristics. If this restricted master problem \RMP{} is infeasible, we use Farkas pricing to find new variables to add to \RMP{}, either until it becomes feasible or until there are no new variables to add, proving the infeasibility of \MP{}. Once \RMP{} is feasible, we solve it to optimality, using reduced cost pricing to verify whether the solution is also optimal for \MP{}. If it is, we have found the optimal solution to \MP{}. Otherwise, we add the corresponding column to \RMP{} and repeat the process \cite{thebook}.

\begin{note}\label{note:distinct_columns}
	All columns in \RMP{} are distinct by design. If a subproblem produced a column already present in \RMP{}, its reduced cost would be non-negative, and it would not be added to \RMP{}.
\end{note}
