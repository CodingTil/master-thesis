\section{Dual Value Stabilization}\label{sec:cg_bp_dvs}
To understand the necessity and method of dual value stabilization, we first consider Lagrangian relaxation. Revisit the following \IP{}, which includes complicating constraints $\mat{A} \vec{x} \geq \vec{b}$ and simpler constraints $\mat{D} \vec{x} \geq \vec{d}$:

\begin{equation*}
\begin{aligned}
z^*_\IP{} = &\min & \vec{c}\transpose \vec{x} & & & \\
&\st & \mat{A} \vec{x} & \geq \vec{b} & \left[\vec{\pi}_\vec{b}\right] & \\
&& \mat{D} \vec{x} & \geq \vec{d} & \left[\vec{\pi}_\vec{d}\right] & \\
&& \vec{x} & \in \mathbb{Z}^n
\end{aligned}
\end{equation*}

Recall that during Dantzig-Wolfe reformulation (Section \ref{sec:cg_bp_dwr}), we decomposed this problem by separating the complicating constraints from the simpler ones, resulting in the following pricing problem:

\begin{equation*}
\begin{aligned}
z^*_\SP{} = -\pi_0 + &\min & \left( \vec{c}\transpose - \vec{\pi}_\vec{b}\transpose \mat{A} \right) \vec{x} & & \\
&\st & \mat{D} \vec{x} & \geq \vec{d} & \left[\vec{\pi}_\vec{d}\right] \\
&& \vec{x} & \in \mathbb{Z}_+^n
\end{aligned}
\end{equation*}

A common approach to compute a lower bound on $z^*_\IP{}$ is to perform a \textbf{Lagrangian relaxation} (\LR{}). In this Lagrangian relaxation, we penalize the violation $(\vec{b} - \mat{A} \vec{x})$ of the complicating constraints using \textbf{Lagrangian multipliers} $\vec{\pi}_\vec{b}$, yielding the following \textbf{Lagrangian subproblem} or \textbf{Lagrangian function} \cite{thebook}:

\begin{equation*}
\begin{aligned}
\LR{\vec{\pi}_\vec{b}} &= & \min \vec{c}\transpose \vec{x} + \vec{\pi}_\vec{b}\transpose \left( \vec{b} - \mat{A}\vec{x} \right) & & \\
& \st & \mat{D} \vec{x} & \geq \vec{d} & \left[\vec{\pi}_\vec{d}\right] \\
&&& \vec{x} & \in \mathbb{Z}_+^n \\
&= & \vec{\pi}_\vec{b} \vec{b} + \min \left( \vec{c} - \vec{\pi}_\vec{b}\transpose \mat{A} \right) \vec{x} & & \\
& \st & \mat{D} \vec{x} & \geq \vec{d} & \left[\vec{\pi}_\vec{d}\right] \\
&&& \vec{x} & \in \mathbb{Z}_+^n
\end{aligned}
\end{equation*}

Notice that both the Lagrangian subproblem and pricing problem are equivalent, except for a constant offset in their objective functions.

The quality of the lower bound provided by the Lagrangian relaxation depends on the choice of the Lagrangian multipliers ($\forall \vec{\pi}_\vec{b} > \vec{0}. \; \LR{\vec{\pi}_\vec{b}} \leq z^*_\IP{}$ \cite{thebook}). To find the greatest lower bound, i.e., the optimal Lagrangian multipliers $\vec{\pi}_\vec{b}^*$ that maximize the Lagrangian subproblem, we solve the \textbf{Lagrangian dual problem} (\LDP{}):

\begin{equation*}
z^*_\LDP{} = \underset{\vec{\pi}_\vec{b} \geq \vec{0}}{\min} \; \LR{\vec{\pi}_\vec{b}}
\end{equation*}

If $z^*_\IP{}$ is finite, an optimal solution $\vec{\pi}_\vec{b}^*$ to the \LDP{} provides a bound equal to the optimal objective value of the \MP{}, i.e., $z^*_\IP{} = z^*_\MP{} = z^*_\LDP{}$. Consequently, the optimal Lagrangian multipliers $\vec{\pi}_\vec{b}^*$ are dual optimal for the \MP{}, and vice versa; optimal dual solutions to the \MP{} are optimal for the \LDP{} \cite{thebook}. The natural question is whether we can leverage this interplay of primal and dual solutions efficiently. For this, let us consider a simple approach of solving the \LDP{} by approximation, the \textbf{subgradient method}.

The Lagrangian function \LR{} is continuous, concave, and subdifferentiable over its finite domain \cite{thebook}. These properties suggest a hill-climbing approach for finding the optimal Lagrangian multipliers $\vec{\pi}_\vec{b}^*$: start with some initial guess, and iteratively improve it by moving in the direction of the subgradient of the Lagrangian function. For a given $\vec{\pi}_\vec{b} > \vec{0}$, an optimal solution $\vec{x}^*$ to $\LR{\vec{\pi}_\vec{b}}$ provides a subgradient $\vec{g} \coloneqq (\vec{b} - \mat{A} \vec{x}^*)$, representing the violation of the complicating constraints for the Lagrangian function at $\vec{\pi}_\vec{b}$ \cite{thebook}. We then update our current guess of the optimal Lagrangian multipliers $\vec{\pi}_\vec{b}^*$ by moving in the direction of the subgradient $\vec{g}$, i.e., $\vec{\pi}_\vec{b}^* \leftarrow \vec{\pi}_\vec{b}^* + \alpha \vec{y}$, where $\alpha$ is a step size. This process is repeated until convergence.

Since a primal optimal solution of \IP{} also yields a dual optimal solution, any \IP{} solver can be viewed as a dual solver for \LDP{}. In the context of a Dantzig-Wolfe reformulation solved by column generation, this becomes particularly interesting, as the pricing problem is equivalent to the Lagrangian subproblem. Column generation can be viewed as a more elaborate update scheme for the Lagrangian multipliers, using multiple solutions to the subproblem to update our guess of the optimal dual values by solving \MP{} \cite{thebook}. Hence, we could also use the subgradient method to solve a Dantzig-Wolfe reformulation, solving the \MP{} only to ensure we find a solution satisfying the complicating constraints.

Both the subgradient method and column generation face a common issue: the updates of the dual values can overshoot the optimal dual values, leading to oscillation and slow convergence of the dual values \cite{thebook, pessoa2013out, bastubbe2018computational}. This is undesirable, as it takes longer to find a good lower bound on the \IP{}, and similarly as it takes longer to find important columns for the \MP{}. To mitigate this issue, sophisticated update schemes have been developed to provide explicit control over updating the dual values in a column generation setting. This \textbf{dual value stabilization} can be achieved by smoothing the dual values over the iterations. At iteration $t$, we determine the smoothed dual values $\widetilde{\vec{\pi}}^t$ by interpolating the current dual values $\vec{\pi}^{t}$ and the previous smoothed dual values $\widetilde{\vec{\pi}}^{t-1}$:

\begin{equation*}
\widetilde{\vec{\pi}}^t \coloneqq \alpha \vec{\pi}^{t} + (1 - \alpha) \widetilde{\vec{\pi}}^{t-1}
\end{equation*}

We can improve upon this by moving from a fixed $\alpha$ to an auto-adaptive $\alpha$-schedule: decrease $\alpha$ if $\vec{\pi}^{t}$ is a good estimate of the optimal dual values, and increase $\alpha$ if it is not \cite{pessoa2013out,pessoa2018automation}. The quality of our guess $\vec{\pi}^{t}$ can be assessed using the subgradients $\left( \vec{b} - \mat{A} \vec{x}^t \right)$ available from the pricing problem. The angle the subgradient forms with $\vec{\pi}^{t} - \widetilde{\vec{\pi}}^{t-1}$ inversely determines the smoothing coefficient $\alpha$ \cite{pessoa2013out,pessoa2018automation}. This approach requires no parameterization.

Since we are already using the subgradients from the pricing problem, we can also correct the direction of our update. This hybrid approach combines the auto-adaptive $\alpha$-schedule with the subgradient ascent method. It requires no parameter tuning and only adds a minimal computational effort. This hybrid method can improve the convergence of the dual values for some instances but does not necessarily outperform the auto-adaptive $\alpha$-schedule for reformulations with identical subproblems. Further details are available in \cite{pessoa2013out, pessoa2018automation}.
